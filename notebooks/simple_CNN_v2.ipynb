{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2484984158827955123\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1489587404\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 17065783024194312859\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "seed = 16\n",
    "np.random.seed(seed)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "os.chdir('C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the test/train data for images and labels.\n",
    "\n",
    "train_data = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\train_data.mat''')['train_data']\n",
    "train_labels = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\train_list.mat''')['labels']\n",
    "test_data = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\test_data.mat''')['test_data']\n",
    "test_labels = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\test_list.mat''')['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 12000)\n",
      "(12000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11990</th>\n",
       "      <th>11991</th>\n",
       "      <th>11992</th>\n",
       "      <th>11993</th>\n",
       "      <th>11994</th>\n",
       "      <th>11995</th>\n",
       "      <th>11996</th>\n",
       "      <th>11997</th>\n",
       "      <th>11998</th>\n",
       "      <th>11999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.370212</td>\n",
       "      <td>0.386276</td>\n",
       "      <td>0.372247</td>\n",
       "      <td>0.363282</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.270990</td>\n",
       "      <td>0.346724</td>\n",
       "      <td>0.394529</td>\n",
       "      <td>0.358653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267177</td>\n",
       "      <td>0.357578</td>\n",
       "      <td>0.420985</td>\n",
       "      <td>0.409833</td>\n",
       "      <td>0.276110</td>\n",
       "      <td>0.346354</td>\n",
       "      <td>0.234670</td>\n",
       "      <td>0.212166</td>\n",
       "      <td>0.337528</td>\n",
       "      <td>0.268254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.370212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454343</td>\n",
       "      <td>0.380271</td>\n",
       "      <td>0.390251</td>\n",
       "      <td>0.280266</td>\n",
       "      <td>0.202480</td>\n",
       "      <td>0.290440</td>\n",
       "      <td>0.306661</td>\n",
       "      <td>0.279821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177962</td>\n",
       "      <td>0.309295</td>\n",
       "      <td>0.417339</td>\n",
       "      <td>0.379545</td>\n",
       "      <td>0.200530</td>\n",
       "      <td>0.253226</td>\n",
       "      <td>0.155548</td>\n",
       "      <td>0.143595</td>\n",
       "      <td>0.309500</td>\n",
       "      <td>0.177095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.386276</td>\n",
       "      <td>0.454343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.371318</td>\n",
       "      <td>0.401308</td>\n",
       "      <td>0.307094</td>\n",
       "      <td>0.206848</td>\n",
       "      <td>0.295721</td>\n",
       "      <td>0.347681</td>\n",
       "      <td>0.256991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192064</td>\n",
       "      <td>0.320620</td>\n",
       "      <td>0.390572</td>\n",
       "      <td>0.373608</td>\n",
       "      <td>0.208791</td>\n",
       "      <td>0.279283</td>\n",
       "      <td>0.152269</td>\n",
       "      <td>0.169688</td>\n",
       "      <td>0.287026</td>\n",
       "      <td>0.204373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.372247</td>\n",
       "      <td>0.380271</td>\n",
       "      <td>0.371318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.357756</td>\n",
       "      <td>0.327126</td>\n",
       "      <td>0.271649</td>\n",
       "      <td>0.324782</td>\n",
       "      <td>0.357688</td>\n",
       "      <td>0.290282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254010</td>\n",
       "      <td>0.353008</td>\n",
       "      <td>0.367482</td>\n",
       "      <td>0.375448</td>\n",
       "      <td>0.302831</td>\n",
       "      <td>0.309191</td>\n",
       "      <td>0.233176</td>\n",
       "      <td>0.188171</td>\n",
       "      <td>0.299682</td>\n",
       "      <td>0.234346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.363282</td>\n",
       "      <td>0.390251</td>\n",
       "      <td>0.401308</td>\n",
       "      <td>0.357756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259415</td>\n",
       "      <td>0.184212</td>\n",
       "      <td>0.273173</td>\n",
       "      <td>0.338933</td>\n",
       "      <td>0.276645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175661</td>\n",
       "      <td>0.299105</td>\n",
       "      <td>0.410328</td>\n",
       "      <td>0.354185</td>\n",
       "      <td>0.175331</td>\n",
       "      <td>0.244246</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>0.135681</td>\n",
       "      <td>0.318807</td>\n",
       "      <td>0.171231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6      \\\n",
       "0  1.000000  0.370212  0.386276  0.372247  0.363282  0.341025  0.270990   \n",
       "1  0.370212  1.000000  0.454343  0.380271  0.390251  0.280266  0.202480   \n",
       "2  0.386276  0.454343  1.000000  0.371318  0.401308  0.307094  0.206848   \n",
       "3  0.372247  0.380271  0.371318  1.000000  0.357756  0.327126  0.271649   \n",
       "4  0.363282  0.390251  0.401308  0.357756  1.000000  0.259415  0.184212   \n",
       "\n",
       "      7         8         9        ...        11990     11991     11992  \\\n",
       "0  0.346724  0.394529  0.358653    ...     0.267177  0.357578  0.420985   \n",
       "1  0.290440  0.306661  0.279821    ...     0.177962  0.309295  0.417339   \n",
       "2  0.295721  0.347681  0.256991    ...     0.192064  0.320620  0.390572   \n",
       "3  0.324782  0.357688  0.290282    ...     0.254010  0.353008  0.367482   \n",
       "4  0.273173  0.338933  0.276645    ...     0.175661  0.299105  0.410328   \n",
       "\n",
       "      11993     11994     11995     11996     11997     11998     11999  \n",
       "0  0.409833  0.276110  0.346354  0.234670  0.212166  0.337528  0.268254  \n",
       "1  0.379545  0.200530  0.253226  0.155548  0.143595  0.309500  0.177095  \n",
       "2  0.373608  0.208791  0.279283  0.152269  0.169688  0.287026  0.204373  \n",
       "3  0.375448  0.302831  0.309191  0.233176  0.188171  0.299682  0.234346  \n",
       "4  0.354185  0.175331  0.244246  0.166500  0.135681  0.318807  0.171231  \n",
       "\n",
       "[5 rows x 12000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(train_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11991</th>\n",
       "      <th>11992</th>\n",
       "      <th>11993</th>\n",
       "      <th>11994</th>\n",
       "      <th>11995</th>\n",
       "      <th>11996</th>\n",
       "      <th>11997</th>\n",
       "      <th>11998</th>\n",
       "      <th>11999</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.370212</td>\n",
       "      <td>0.386276</td>\n",
       "      <td>0.372247</td>\n",
       "      <td>0.363282</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.270990</td>\n",
       "      <td>0.346724</td>\n",
       "      <td>0.394529</td>\n",
       "      <td>0.358653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357578</td>\n",
       "      <td>0.420985</td>\n",
       "      <td>0.409833</td>\n",
       "      <td>0.276110</td>\n",
       "      <td>0.346354</td>\n",
       "      <td>0.234670</td>\n",
       "      <td>0.212166</td>\n",
       "      <td>0.337528</td>\n",
       "      <td>0.268254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.370212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454343</td>\n",
       "      <td>0.380271</td>\n",
       "      <td>0.390251</td>\n",
       "      <td>0.280266</td>\n",
       "      <td>0.202480</td>\n",
       "      <td>0.290440</td>\n",
       "      <td>0.306661</td>\n",
       "      <td>0.279821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309295</td>\n",
       "      <td>0.417339</td>\n",
       "      <td>0.379545</td>\n",
       "      <td>0.200530</td>\n",
       "      <td>0.253226</td>\n",
       "      <td>0.155548</td>\n",
       "      <td>0.143595</td>\n",
       "      <td>0.309500</td>\n",
       "      <td>0.177095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.386276</td>\n",
       "      <td>0.454343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.371318</td>\n",
       "      <td>0.401308</td>\n",
       "      <td>0.307094</td>\n",
       "      <td>0.206848</td>\n",
       "      <td>0.295721</td>\n",
       "      <td>0.347681</td>\n",
       "      <td>0.256991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320620</td>\n",
       "      <td>0.390572</td>\n",
       "      <td>0.373608</td>\n",
       "      <td>0.208791</td>\n",
       "      <td>0.279283</td>\n",
       "      <td>0.152269</td>\n",
       "      <td>0.169688</td>\n",
       "      <td>0.287026</td>\n",
       "      <td>0.204373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.372247</td>\n",
       "      <td>0.380271</td>\n",
       "      <td>0.371318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.357756</td>\n",
       "      <td>0.327126</td>\n",
       "      <td>0.271649</td>\n",
       "      <td>0.324782</td>\n",
       "      <td>0.357688</td>\n",
       "      <td>0.290282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353008</td>\n",
       "      <td>0.367482</td>\n",
       "      <td>0.375448</td>\n",
       "      <td>0.302831</td>\n",
       "      <td>0.309191</td>\n",
       "      <td>0.233176</td>\n",
       "      <td>0.188171</td>\n",
       "      <td>0.299682</td>\n",
       "      <td>0.234346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.363282</td>\n",
       "      <td>0.390251</td>\n",
       "      <td>0.401308</td>\n",
       "      <td>0.357756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259415</td>\n",
       "      <td>0.184212</td>\n",
       "      <td>0.273173</td>\n",
       "      <td>0.338933</td>\n",
       "      <td>0.276645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299105</td>\n",
       "      <td>0.410328</td>\n",
       "      <td>0.354185</td>\n",
       "      <td>0.175331</td>\n",
       "      <td>0.244246</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>0.135681</td>\n",
       "      <td>0.318807</td>\n",
       "      <td>0.171231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.370212  0.386276  0.372247  0.363282  0.341025  0.270990   \n",
       "1  0.370212  1.000000  0.454343  0.380271  0.390251  0.280266  0.202480   \n",
       "2  0.386276  0.454343  1.000000  0.371318  0.401308  0.307094  0.206848   \n",
       "3  0.372247  0.380271  0.371318  1.000000  0.357756  0.327126  0.271649   \n",
       "4  0.363282  0.390251  0.401308  0.357756  1.000000  0.259415  0.184212   \n",
       "\n",
       "          7         8         9  ...       11991     11992     11993  \\\n",
       "0  0.346724  0.394529  0.358653  ...    0.357578  0.420985  0.409833   \n",
       "1  0.290440  0.306661  0.279821  ...    0.309295  0.417339  0.379545   \n",
       "2  0.295721  0.347681  0.256991  ...    0.320620  0.390572  0.373608   \n",
       "3  0.324782  0.357688  0.290282  ...    0.353008  0.367482  0.375448   \n",
       "4  0.273173  0.338933  0.276645  ...    0.299105  0.410328  0.354185   \n",
       "\n",
       "      11994     11995     11996     11997     11998     11999  label  \n",
       "0  0.276110  0.346354  0.234670  0.212166  0.337528  0.268254      1  \n",
       "1  0.200530  0.253226  0.155548  0.143595  0.309500  0.177095      1  \n",
       "2  0.208791  0.279283  0.152269  0.169688  0.287026  0.204373      1  \n",
       "3  0.302831  0.309191  0.233176  0.188171  0.299682  0.234346      1  \n",
       "4  0.175331  0.244246  0.166500  0.135681  0.318807  0.171231      1  \n",
       "\n",
       "[5 rows x 12001 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [item for label in train_labels for item in label] \n",
    "df2 = pd.DataFrame({'label':labels})\n",
    "\n",
    "pre_split = pd.concat([df, df2], axis=1)\n",
    "pre_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate = train_test_split(df, test_size = 0.2, stratify=train_labels, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11990</th>\n",
       "      <th>11991</th>\n",
       "      <th>11992</th>\n",
       "      <th>11993</th>\n",
       "      <th>11994</th>\n",
       "      <th>11995</th>\n",
       "      <th>11996</th>\n",
       "      <th>11997</th>\n",
       "      <th>11998</th>\n",
       "      <th>11999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>0.322709</td>\n",
       "      <td>0.267931</td>\n",
       "      <td>0.281449</td>\n",
       "      <td>0.297712</td>\n",
       "      <td>0.259242</td>\n",
       "      <td>0.335441</td>\n",
       "      <td>0.349134</td>\n",
       "      <td>0.394268</td>\n",
       "      <td>0.259501</td>\n",
       "      <td>0.293976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390242</td>\n",
       "      <td>0.365563</td>\n",
       "      <td>0.278592</td>\n",
       "      <td>0.322319</td>\n",
       "      <td>0.319473</td>\n",
       "      <td>0.353347</td>\n",
       "      <td>0.264001</td>\n",
       "      <td>0.372329</td>\n",
       "      <td>0.300654</td>\n",
       "      <td>0.365475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>0.334906</td>\n",
       "      <td>0.243707</td>\n",
       "      <td>0.275596</td>\n",
       "      <td>0.306293</td>\n",
       "      <td>0.223655</td>\n",
       "      <td>0.365035</td>\n",
       "      <td>0.372774</td>\n",
       "      <td>0.397690</td>\n",
       "      <td>0.267229</td>\n",
       "      <td>0.328474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351376</td>\n",
       "      <td>0.336478</td>\n",
       "      <td>0.251471</td>\n",
       "      <td>0.305041</td>\n",
       "      <td>0.367305</td>\n",
       "      <td>0.382617</td>\n",
       "      <td>0.308046</td>\n",
       "      <td>0.337379</td>\n",
       "      <td>0.244758</td>\n",
       "      <td>0.356931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>0.281262</td>\n",
       "      <td>0.159415</td>\n",
       "      <td>0.162632</td>\n",
       "      <td>0.281583</td>\n",
       "      <td>0.168625</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.362225</td>\n",
       "      <td>0.381443</td>\n",
       "      <td>0.235047</td>\n",
       "      <td>0.311864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331580</td>\n",
       "      <td>0.317978</td>\n",
       "      <td>0.219133</td>\n",
       "      <td>0.246647</td>\n",
       "      <td>0.379795</td>\n",
       "      <td>0.341016</td>\n",
       "      <td>0.312345</td>\n",
       "      <td>0.325242</td>\n",
       "      <td>0.232786</td>\n",
       "      <td>0.351501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>0.341854</td>\n",
       "      <td>0.340799</td>\n",
       "      <td>0.315841</td>\n",
       "      <td>0.341646</td>\n",
       "      <td>0.323526</td>\n",
       "      <td>0.324015</td>\n",
       "      <td>0.291754</td>\n",
       "      <td>0.319159</td>\n",
       "      <td>0.323100</td>\n",
       "      <td>0.322483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227378</td>\n",
       "      <td>0.350138</td>\n",
       "      <td>0.339472</td>\n",
       "      <td>0.366221</td>\n",
       "      <td>0.262715</td>\n",
       "      <td>0.292098</td>\n",
       "      <td>0.302035</td>\n",
       "      <td>0.219769</td>\n",
       "      <td>0.284869</td>\n",
       "      <td>0.211938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9576</th>\n",
       "      <td>0.372642</td>\n",
       "      <td>0.324510</td>\n",
       "      <td>0.311419</td>\n",
       "      <td>0.393962</td>\n",
       "      <td>0.351303</td>\n",
       "      <td>0.346245</td>\n",
       "      <td>0.291129</td>\n",
       "      <td>0.328887</td>\n",
       "      <td>0.316775</td>\n",
       "      <td>0.301948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274405</td>\n",
       "      <td>0.366048</td>\n",
       "      <td>0.355431</td>\n",
       "      <td>0.369575</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.315565</td>\n",
       "      <td>0.288739</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>0.269478</td>\n",
       "      <td>0.219351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6      \\\n",
       "4346  0.322709  0.267931  0.281449  0.297712  0.259242  0.335441  0.349134   \n",
       "1895  0.334906  0.243707  0.275596  0.306293  0.223655  0.365035  0.372774   \n",
       "8064  0.281262  0.159415  0.162632  0.281583  0.168625  0.301370  0.362225   \n",
       "2138  0.341854  0.340799  0.315841  0.341646  0.323526  0.324015  0.291754   \n",
       "9576  0.372642  0.324510  0.311419  0.393962  0.351303  0.346245  0.291129   \n",
       "\n",
       "         7         8         9        ...        11990     11991     11992  \\\n",
       "4346  0.394268  0.259501  0.293976    ...     0.390242  0.365563  0.278592   \n",
       "1895  0.397690  0.267229  0.328474    ...     0.351376  0.336478  0.251471   \n",
       "8064  0.381443  0.235047  0.311864    ...     0.331580  0.317978  0.219133   \n",
       "2138  0.319159  0.323100  0.322483    ...     0.227378  0.350138  0.339472   \n",
       "9576  0.328887  0.316775  0.301948    ...     0.274405  0.366048  0.355431   \n",
       "\n",
       "         11993     11994     11995     11996     11997     11998     11999  \n",
       "4346  0.322319  0.319473  0.353347  0.264001  0.372329  0.300654  0.365475  \n",
       "1895  0.305041  0.367305  0.382617  0.308046  0.337379  0.244758  0.356931  \n",
       "8064  0.246647  0.379795  0.341016  0.312345  0.325242  0.232786  0.351501  \n",
       "2138  0.366221  0.262715  0.292098  0.302035  0.219769  0.284869  0.211938  \n",
       "9576  0.369575  0.298750  0.315565  0.288739  0.181200  0.269478  0.219351  \n",
       "\n",
       "[5 rows x 12000 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#might have finally figured out how to stratify the image data...\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels, test_size=0.2, stratify=train_labels, random_state=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on the data.... X_train X_val are already resized from 0-255 to 0-1. No need to transform these arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the y_train and y_val to categoricals  ***not sure if this is needed**\n",
    "y_train_onehot = to_categorical(y_train)\n",
    "y_val_onehot = to_categorical(y_val)\n",
    "num_classes = y_val.shape[0]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600, 12000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a simple CNN to start\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_51 (Conv2D)           (None, 2398, 2998, 64)    64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 599, 749, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 148, 185, 32)      247840    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 37, 46, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 7, 9, 16)          61968     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 1, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2400)              156000    \n",
      "=================================================================\n",
      "Total params: 467,984\n",
      "Trainable params: 467,984\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (9600, 12000, 0)\n",
    "\n",
    "# create the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (11, 11), strides=4, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Conv2D(32, (11, 11), strides=4, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Conv2D(16, (11, 11), strides=4, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "     \n",
    "\n",
    "# Compile model\n",
    "epochs = 25\n",
    "lrate = 0.003\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_51_input to have 4 dimensions, but got array with shape (9600, 12000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-62b8744a2514>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1630\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1631\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1476\u001b[1;33m                                     exception_prefix='input')\n\u001b[0m\u001b[0;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[0;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    111\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_51_input to have 4 dimensions, but got array with shape (9600, 12000)"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=32)\n",
    "scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
